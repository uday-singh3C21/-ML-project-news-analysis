{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eed1ba2-aaa1-4ef8-9f50-8b0343a761e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from newsapi import NewsApiClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from apscheduler.schedulers.background import BackgroundScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59660b8-7d2e-4961-96b3-65a209102c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key for NewsAPI\n",
    "API_KEY = 'bcae1bfec35f4e78a3cdc7accdbffd86'\n",
    "newsapi = NewsApiClient(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69cd428-b724-4471-bcb0-25bb9f72ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load or initialize model and vectorizer\n",
    "try:\n",
    "    with open(\"sentiment_model.pkl\", \"rb\") as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "    with open(\"vectorizer.pkl\", \"rb\") as vec_file:\n",
    "        vectorizer = pickle.load(vec_file)\n",
    "    print(\"Model and vectorizer loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing model found. Training from scratch.\")\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ee5fcc-9bb6-415d-ad5b-77a82d12d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch real-time news\n",
    "def fetch_real_time_news():\n",
    "    try:\n",
    "        articles = newsapi.get_everything(q='stock market', language='en', sort_by='publishedAt')\n",
    "        news_data = [{\n",
    "            'publishedAt': article['publishedAt'],\n",
    "            'text': f\"{article['title']} {article['description']} {article['content']}\",\n",
    "            'link': article['url'],\n",
    "            'video': ''  # Empty for now\n",
    "        } for article in articles['articles']]\n",
    "        return pd.DataFrame(news_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47dde81-c03b-491f-b804-c5d34006e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602b2a47-6190-48cd-aaf9-e4eab6d87a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed sentiment score (-10 to 10)\n",
    "def generate_sentiment_score(prediction):\n",
    "    return np.random.randint(-10, 11)  # Randomized for now, can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "337bd9ef-fd93-459f-a873-b11562d56fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model\n",
    "def retrain_model(new_data):\n",
    "    global model, vectorizer\n",
    "    try:\n",
    "        labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
    "    except FileNotFoundError:\n",
    "        labeled_data = pd.DataFrame(columns=[\"publishedAt\", \"clean_text\", \"sentiment\", \"link\", \"detailed_sentiment\", \"video\"])\n",
    "    \n",
    "    labeled_data = pd.concat([labeled_data, new_data], ignore_index=True)\n",
    "    \n",
    "    X = labeled_data['clean_text']\n",
    "    y = labeled_data['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    with open(\"sentiment_model.pkl\", \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "    with open(\"vectorizer.pkl\", \"wb\") as vec_file:\n",
    "        pickle.dump(vectorizer, vec_file)\n",
    "    \n",
    "    print(\"Model retrained and updated successfully!\")\n",
    "    evaluate_model(X_test_vec, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c3ac222-387c-4c50-8962-6d9bf859be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(X_test_vec, y_test):\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "    print(\"\\nModel Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76065141-0bb6-44db-8406-c211a92aba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated training pipeline\n",
    "def automate_training():\n",
    "    print(\"Fetching and processing new news data...\")\n",
    "    real_time_data = fetch_real_time_news()\n",
    "    if not real_time_data.empty:\n",
    "        real_time_data['clean_text'] = real_time_data['text'].apply(clean_text)\n",
    "        real_time_data['sentiment'] = model.predict(vectorizer.transform(real_time_data['clean_text']))\n",
    "        real_time_data['detailed_sentiment'] = real_time_data['sentiment'].apply(generate_sentiment_score)\n",
    "        \n",
    "        real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']].to_csv(\"labeled_news_data1.csv\", mode='a', header=False, index=False)\n",
    "        retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
    "    else:\n",
    "        print(\"No new data fetched.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01f1f5d8-6503-4ef9-838b-577dd27840ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated model training started. Running every 15 seconds...\n",
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:15:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:15:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:15:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:15:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:16:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:16:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:16:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:16:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:17:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:17:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:17:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:17:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:18:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:18:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:18:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:18:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:19:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:19:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:19:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:19:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:20:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:20:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:20:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:20:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:21:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:21:27 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:21:42 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:21:57 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing new news data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job \"automate_training (trigger: interval[0:00:15], next run at: 2025-02-10 20:22:12 IST)\" raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/apscheduler/executors/base.py\", line 131, in run_job\n",
      "    retval = job.func(*job.args, **job.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/322311133.py\", line 11, in automate_training\n",
      "    retrain_model(real_time_data[['publishedAt', 'clean_text', 'sentiment', 'link', 'detailed_sentiment', 'video']])\n",
      "  File \"/var/folders/wp/l1lbtpb57rl387801fcn64ch0000gn/T/ipykernel_11976/3090690995.py\", line 5, in retrain_model\n",
      "    labeled_data = pd.read_csv(\"labeled_news_data1.csv\")\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 626, in _read\n",
      "    return parser.read(nrows)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 838, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler stopped.\n"
     ]
    }
   ],
   "source": [
    "# Scheduler to run training every 15 seconds\n",
    "scheduler = BackgroundScheduler()\n",
    "scheduler.add_job(automate_training, 'interval', seconds=15)\n",
    "scheduler.start()\n",
    "\n",
    "print(\"Automated model training started. Running every 15 seconds...\")\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(15)\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    scheduler.shutdown()\n",
    "    print(\"Scheduler stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a47800a-bb47-433f-baee-2b6efd43f4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load labeled dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabeled_news_data1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublishedAt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_text\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetailed_sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 6 fields in line 97, saw 11\n"
     ]
    }
   ],
   "source": [
    "# Load labeled dataset\n",
    "file_path = \"labeled_news_data1.csv\"\n",
    "df = pd.read_csv(file_path, names=[\"publishedAt\", \"clean_text\", \"sentiment\", \"link\", \"detailed_sentiment\", \"video\"])  # Ensure correct column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b9f9895-c95f-46c5-b381-62855b7c7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Accuracy: 1.0\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    positive       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectorize text data\n",
    "with open(\"vectorizer.pkl\", \"rb\") as vec_file:\n",
    "    vectorizer = pickle.load(vec_file)\n",
    "\n",
    "X = vectorizer.transform(df['clean_text'])  # Transform existing data\n",
    "y = df['sentiment']  # Labels (-1 = Negative, 0 = Neutral, 1 = Positive)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"sentiment_model.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Accuracy and Classification Report\n",
    "print(\"\\n Model Accuracy:\", accuracy)\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negative\", \"Neutral\", \"Positive\"], yticklabels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94817d6-e773-4435-b12c-15b4fda4e1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
